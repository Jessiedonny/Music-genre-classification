{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395248cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ebb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df1=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/alternative.csv\",keep_default_na=False,na_values=['?'])\n",
    "df2=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/blues.csv\",keep_default_na=False,na_values=['?'])\n",
    "df3=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/childrens music.csv\",keep_default_na=False,na_values=['?'])\n",
    "df4=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/comedy.csv\",keep_default_na=False,na_values=['?'])\n",
    "df5=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/electronic.csv\",keep_default_na=False,na_values=['?'])\n",
    "df6=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/folk.csv\",keep_default_na=False,na_values=['?'])\n",
    "df7=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/hip-hop.csv\",keep_default_na=False,na_values=['?'])\n",
    "df8=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/movie.csv\",keep_default_na=False,na_values=['?'])\n",
    "df9=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/ska.csv\",keep_default_na=False,na_values=['?'])\n",
    "df10=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/training-data/soul.csv\",keep_default_na=False,na_values=['?'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0bd07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure of training sets are identical\n"
     ]
    }
   ],
   "source": [
    "#check if the 10 datasets have same structure\n",
    "training_dfs=[df2,df3,df4,df5,df6,df7,df8,df9,df10]\n",
    "if all([set(df1.columns)==set(tdf.columns) for tdf in training_dfs]):\n",
    "    print(\"structure of training sets are identical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1d1b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge to one dataset\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d088976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data\n",
    "#1) split the dataset to a training set(90%) and avalidation set(10%) to avoid data leakage\n",
    "x=df.drop(\"genre\", axis = 1)\n",
    "y=df[\"genre\"]\n",
    "train_x,val_x,train_y,val_y=train_test_split(x, y, test_size=0.1, random_state=309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281e48fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popularity            int64\n",
       "acousticness        float64\n",
       "danceability        float64\n",
       "duration_ms           int64\n",
       "energy              float64\n",
       "instrumentalness    float64\n",
       "key                   int64\n",
       "liveness            float64\n",
       "loudness            float64\n",
       "mode                  int64\n",
       "speechiness         float64\n",
       "tempo               float64\n",
       "time_signature        int64\n",
       "valence             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2) drop irrelavant features and encode categorical features\n",
    "train_x_clean=train_x.drop([\"instance_id\",\"artist_name\",\"track_name\",\"track_id\"], axis = 1)\n",
    "key_encoder=LabelEncoder()\n",
    "train_x_clean[\"key\"]=key_encoder.fit_transform(train_x_clean[\"key\"])\n",
    "mode_encoder=LabelEncoder()\n",
    "train_x_clean[\"mode\"]=mode_encoder.fit_transform(train_x_clean[\"mode\"])\n",
    "ts_encoder=LabelEncoder()\n",
    "train_x_clean[\"time_signature\"]=ts_encoder.fit_transform(train_x_clean[\"time_signature\"])\n",
    "\n",
    "#3) encode target variable\n",
    "genre_encoder=LabelEncoder()\n",
    "train_y_encoded=genre_encoder.fit_transform(train_y)\n",
    "\n",
    "train_x_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9969fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity             0\n",
      "acousticness           0\n",
      "danceability           0\n",
      "duration_ms         9015\n",
      "energy                 0\n",
      "instrumentalness       0\n",
      "key                    0\n",
      "liveness               0\n",
      "loudness               0\n",
      "mode                   0\n",
      "speechiness            0\n",
      "tempo                  0\n",
      "time_signature         0\n",
      "valence                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check missing values\n",
    "print(train_x_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f32316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values \n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "key                 0\n",
      "liveness            0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "valence             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#4) impute missing values\n",
    "\n",
    "# duration_ms\n",
    "from sklearn.impute import KNNImputer\n",
    "dms_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train_x_clean[\"duration_ms\"]=train_x_clean[\"duration_ms\"].replace(-1,np.NaN)\n",
    "train_x_clean[\"duration_ms\"] = dms_imputer.fit_transform(train_x_clean[[\"duration_ms\"]])\n",
    "# tempo\n",
    "tempo_imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "train_x_clean[\"tempo\"] = tempo_imputer.fit_transform(train_x_clean[[\"tempo\"]])\n",
    "\n",
    "print(\"The number of missing values \")\n",
    "print(train_x_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10669831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.513</td>\n",
       "      <td>301213.000000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3840</td>\n",
       "      <td>-9.462</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>118.856081</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>48</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.843</td>\n",
       "      <td>344120.000000</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>-10.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>119.564000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>36</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>0.817</td>\n",
       "      <td>227367.444685</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>-14.537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>127.846000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.367</td>\n",
       "      <td>122000.000000</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>-11.898</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>125.761000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3438</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.889</td>\n",
       "      <td>227367.444685</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>-8.148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>97.176000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>55</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.865</td>\n",
       "      <td>227367.444685</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>-6.652</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>95.307000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>31</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.633</td>\n",
       "      <td>164853.000000</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>-12.827</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>131.639000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>37</td>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.502</td>\n",
       "      <td>150667.000000</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>-7.473</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>101.382000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.771</td>\n",
       "      <td>164516.000000</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>-4.883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>118.856081</td>\n",
       "      <td>2</td>\n",
       "      <td>0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>50</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.247</td>\n",
       "      <td>256080.000000</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>-10.195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>118.856081</td>\n",
       "      <td>2</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40535 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      popularity  acousticness  danceability    duration_ms  energy  \\\n",
       "3874          27        0.0405         0.513  301213.000000   0.848   \n",
       "981           48        0.0126         0.843  344120.000000   0.448   \n",
       "4966          36        0.7870         0.817  227367.444685   0.189   \n",
       "3760          25        0.0267         0.367  122000.000000   0.931   \n",
       "3438          50        0.0362         0.889  227367.444685   0.557   \n",
       "...          ...           ...           ...            ...     ...   \n",
       "3475          55        0.0611         0.865  227367.444685   0.641   \n",
       "4617          31        0.6880         0.633  164853.000000   0.537   \n",
       "89            37        0.7010         0.502  150667.000000   0.659   \n",
       "319           50        0.0719         0.771  164516.000000   0.834   \n",
       "4241          50        0.1740         0.247  256080.000000   0.419   \n",
       "\n",
       "      instrumentalness  key  liveness  loudness  mode  speechiness  \\\n",
       "3874          0.000015    5    0.3840    -9.462     0       0.0563   \n",
       "981           0.000944    3    0.0826   -10.398     0       0.3160   \n",
       "4966          0.000000    3    0.0843   -14.537     0       0.0713   \n",
       "3760          0.000000    2    0.2400   -11.898     1       0.0442   \n",
       "3438          0.000000    7    0.3320    -8.148     0       0.3520   \n",
       "...                ...  ...       ...       ...   ...          ...   \n",
       "3475          0.000107    1    0.2180    -6.652     1       0.1620   \n",
       "4617          0.000000    7    0.2870   -12.827     1       0.0306   \n",
       "89            0.000225    5    0.1150    -7.473     0       0.0416   \n",
       "319           0.013400    5    0.1630    -4.883     1       0.0481   \n",
       "4241          0.006560    0    0.2220   -10.195     1       0.0313   \n",
       "\n",
       "           tempo  time_signature  valence  \n",
       "3874  118.856081               2    0.685  \n",
       "981   119.564000               2    0.172  \n",
       "4966  127.846000               2    0.566  \n",
       "3760  125.761000               2    0.925  \n",
       "3438   97.176000               2    0.805  \n",
       "...          ...             ...      ...  \n",
       "3475   95.307000               2    0.762  \n",
       "4617  131.639000               2    0.736  \n",
       "89    101.382000               2    0.841  \n",
       "319   118.856081               2    0.280  \n",
       "4241  118.856081               2    0.273  \n",
       "\n",
       "[40535 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5) remove outliers\n",
    "from scipy import stats\n",
    "train_x_clean[(np.abs(stats.zscore(train_x_clean)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "016cbcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.01264933 0.84255365 0.0677637  0.44832917 0.00095065\n",
      " 0.27272727 0.07108141 0.66479414 0.         0.31162495 0.46465345\n",
      " 0.66666667 0.172     ]\n"
     ]
    }
   ],
   "source": [
    "#6) Scale the data\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(train_x_clean)\n",
    "print(x_scaled[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fc3e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7) perform feature selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "selector=SelectKBest(chi2, k=12)\n",
    "train_x_final = selector.fit_transform(x_scaled, train_y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ff97a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.01264933, 0.84255365, 0.44832917, 0.00095065,\n",
       "       0.07108141, 0.66479414, 0.        , 0.31162495, 0.46465345,\n",
       "       0.66666667, 0.172     ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_final[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1208c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7) Transform the validation set\n",
    "val_x_clean=val_x.drop([\"instance_id\",\"artist_name\",\"track_name\",\"track_id\"], axis = 1)\n",
    "val_x_clean[\"key\"]=key_encoder.transform(val_x_clean[\"key\"])\n",
    "val_x_clean[\"mode\"]=mode_encoder.transform(val_x_clean[\"mode\"])\n",
    "val_x_clean[\"time_signature\"]=ts_encoder.transform(val_x_clean[\"time_signature\"])\n",
    "val_y_encoded=genre_encoder.transform(val_y)\n",
    "val_x_clean[\"duration_ms\"]=val_x_clean[\"duration_ms\"].replace(-1,np.NaN)\n",
    "val_x_clean[\"duration_ms\"] = dms_imputer.transform(val_x_clean[[\"duration_ms\"]])\n",
    "val_x_clean[\"tempo\"] = tempo_imputer.transform(val_x_clean[[\"tempo\"]])\n",
    "val_x_scaled=min_max_scaler.transform(val_x_clean)\n",
    "val_x_final=selector.transform(val_x_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f1141",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03fba5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.42      0.35       507\n",
      "           1       0.40      0.43      0.42       507\n",
      "           2       0.32      0.27      0.30       452\n",
      "           3       0.94      0.95      0.94       504\n",
      "           4       0.59      0.59      0.59       473\n",
      "           5       0.41      0.44      0.42       493\n",
      "           6       0.65      0.68      0.67       542\n",
      "           7       0.76      0.66      0.71       524\n",
      "           8       0.67      0.61      0.64       493\n",
      "           9       0.35      0.24      0.28       505\n",
      "\n",
      "    accuracy                           0.53      5000\n",
      "   macro avg       0.54      0.53      0.53      5000\n",
      "weighted avg       0.54      0.53      0.54      5000\n",
      "\n",
      "CPU times: user 1.31 s, sys: 11.3 ms, total: 1.32 s\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnmodel = KNeighborsClassifier(n_neighbors=5)\n",
    "knnmodel.fit(train_x_final, train_y_encoded)\n",
    "pred_knn = knnmodel.predict(val_x_final)\n",
    "acc_knn=accuracy_score(val_y_encoded,pred_knn)\n",
    "print(acc_knn)\n",
    "print(classification_report(val_y_encoded,pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30f37eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.37      0.36       507\n",
      "           1       0.56      0.51      0.54       507\n",
      "           2       0.41      0.25      0.31       452\n",
      "           3       0.99      0.94      0.96       504\n",
      "           4       0.70      0.67      0.68       473\n",
      "           5       0.49      0.62      0.54       493\n",
      "           6       0.70      0.86      0.77       542\n",
      "           7       0.77      0.80      0.78       524\n",
      "           8       0.74      0.69      0.71       493\n",
      "           9       0.41      0.41      0.41       505\n",
      "\n",
      "    accuracy                           0.62      5000\n",
      "   macro avg       0.61      0.61      0.61      5000\n",
      "weighted avg       0.61      0.62      0.61      5000\n",
      "\n",
      "CPU times: user 8.96 s, sys: 89.2 ms, total: 9.05 s\n",
      "Wall time: 9.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#random forest\n",
    "#rfmodel = RandomForestClassifier(n_estimators=1200,min_samples_split=10,min_samples_leaf=2,max_features='auto',\n",
    "#                                 max_depth=70,bootstrap= True)\n",
    "rfmodel = RandomForestClassifier(max_depth=15)\n",
    "rfmodel.fit(train_x_final, train_y_encoded)\n",
    "pred_rf = rfmodel.predict(val_x_final)\n",
    "acc_rf=accuracy_score(val_y_encoded,pred_rf)\n",
    "print(acc_rf)\n",
    "print(classification_report(val_y_encoded,pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e15683a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.40      0.38       507\n",
      "           1       0.48      0.48      0.48       507\n",
      "           2       0.48      0.31      0.37       452\n",
      "           3       0.96      0.95      0.95       504\n",
      "           4       0.58      0.51      0.54       473\n",
      "           5       0.43      0.60      0.50       493\n",
      "           6       0.66      0.83      0.74       542\n",
      "           7       0.77      0.71      0.74       524\n",
      "           8       0.68      0.60      0.64       493\n",
      "           9       0.35      0.31      0.33       505\n",
      "\n",
      "    accuracy                           0.58      5000\n",
      "   macro avg       0.58      0.57      0.57      5000\n",
      "weighted avg       0.58      0.58      0.57      5000\n",
      "\n",
      "CPU times: user 381 ms, sys: 5.97 ms, total: 387 ms\n",
      "Wall time: 412 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtmodel = DecisionTreeClassifier(max_depth=10)\n",
    "dtmodel.fit(train_x_final, train_y_encoded)\n",
    "pred_dt = dtmodel.predict(val_x_final)\n",
    "acc_dt=accuracy_score(val_y_encoded,pred_dt)\n",
    "print(acc_dt)\n",
    "print(classification_report(val_y_encoded,pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7176c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.39       507\n",
      "           1       0.46      0.31      0.37       507\n",
      "           2       0.09      0.05      0.06       452\n",
      "           3       0.94      0.95      0.95       504\n",
      "           4       0.59      0.63      0.61       473\n",
      "           5       0.48      0.53      0.50       493\n",
      "           6       0.68      0.80      0.74       542\n",
      "           7       0.67      0.72      0.69       524\n",
      "           8       0.50      0.67      0.57       493\n",
      "           9       0.40      0.32      0.35       505\n",
      "\n",
      "    accuracy                           0.55      5000\n",
      "   macro avg       0.52      0.54      0.52      5000\n",
      "weighted avg       0.52      0.55      0.53      5000\n",
      "\n",
      "CPU times: user 17.9 s, sys: 580 ms, total: 18.5 s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrmodel = LogisticRegression(max_iter=400)\n",
    "lrmodel.fit(train_x_final, train_y_encoded)\n",
    "pred_lr = lrmodel.predict(val_x_final)\n",
    "acc_lr=accuracy_score(val_y_encoded,pred_lr)\n",
    "print(acc_lr)\n",
    "print(classification_report(val_y_encoded,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b7e199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35       507\n",
      "           1       0.53      0.52      0.53       507\n",
      "           2       0.33      0.30      0.31       452\n",
      "           3       0.98      0.95      0.96       504\n",
      "           4       0.70      0.66      0.68       473\n",
      "           5       0.49      0.54      0.51       493\n",
      "           6       0.73      0.77      0.75       542\n",
      "           7       0.78      0.77      0.78       524\n",
      "           8       0.72      0.68      0.70       493\n",
      "           9       0.39      0.40      0.40       505\n",
      "\n",
      "    accuracy                           0.60      5000\n",
      "   macro avg       0.60      0.59      0.60      5000\n",
      "weighted avg       0.60      0.60      0.60      5000\n",
      "\n",
      "CPU times: user 5min 27s, sys: 3.65 s, total: 5min 31s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbmodel = GradientBoostingClassifier(max_depth=10)\n",
    "gbmodel.fit(train_x_final, train_y_encoded)\n",
    "pred_gb = gbmodel.predict(val_x_final)\n",
    "acc_gb=accuracy_score(val_y_encoded,pred_gb)\n",
    "print(acc_gb)\n",
    "print(classification_report(val_y_encoded,pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff5e4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.46      0.43       507\n",
      "           1       0.55      0.53      0.54       507\n",
      "           2       0.57      0.23      0.33       452\n",
      "           3       0.98      0.95      0.96       504\n",
      "           4       0.69      0.65      0.67       473\n",
      "           5       0.48      0.63      0.55       493\n",
      "           6       0.69      0.85      0.76       542\n",
      "           7       0.77      0.79      0.78       524\n",
      "           8       0.73      0.65      0.69       493\n",
      "           9       0.40      0.43      0.42       505\n",
      "\n",
      "    accuracy                           0.62      5000\n",
      "   macro avg       0.63      0.62      0.61      5000\n",
      "weighted avg       0.63      0.62      0.62      5000\n",
      "\n",
      "CPU times: user 2min 49s, sys: 2.93 s, total: 2min 52s\n",
      "Wall time: 48.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jessie/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#MLPClassifier  - Multi layer perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpmodel = MLPClassifier()\n",
    "mlpmodel.fit(train_x_final, train_y_encoded)\n",
    "pred_mlp = mlpmodel.predict(val_x_final)\n",
    "acc_mlp=accuracy_score(val_y_encoded,pred_mlp)\n",
    "print(acc_mlp)\n",
    "print(classification_report(val_y_encoded,pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5af571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]}\n",
      "{'n_estimators': 1000, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "#these codes are to find the best parameter of random forest model\n",
    "#reference: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "print(random_grid)\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, n_jobs = -1)\n",
    "rf_random.fit(train_x_final, train_y_encoded)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a75ce6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values \n",
      "popularity             0\n",
      "acousticness           0\n",
      "danceability           0\n",
      "duration_ms            0\n",
      "energy                 0\n",
      "instrumentalness       0\n",
      "key                    0\n",
      "liveness               0\n",
      "loudness               0\n",
      "mode                   0\n",
      "speechiness            0\n",
      "tempo               4598\n",
      "time_signature         0\n",
      "valence                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and transform the test set\n",
    "df_test=pd.read_csv(\"/Users/Jessie/Documents/JupyterNotebook/ass3data/test-data/test.csv\",keep_default_na=False,na_values=['?'])\n",
    "test_x=df_test.drop([\"instance_id\",\"artist_name\",\"track_name\",\"track_id\"], axis = 1)\n",
    "test_x[\"key\"]=key_encoder.transform(test_x[\"key\"])\n",
    "test_x[\"mode\"]=mode_encoder.transform(test_x[\"mode\"])\n",
    "test_x[\"time_signature\"] = test_x[\"time_signature\"] .map(lambda s: '<unknown>'  if s not in ts_encoder.classes_ else s)\n",
    "ts_encoder.classes_ = np.append(ts_encoder.classes_, '<unknown>' )\n",
    "test_x[\"time_signature\"]=ts_encoder.transform(test_x[\"time_signature\"])\n",
    "print(\"The number of missing values \")\n",
    "print(test_x.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45bdf588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.27083333e-01 2.56023140e-01 6.87264100e-01 9.49939126e-01\n",
      "  2.57804632e-01 8.69785338e-02 8.13837730e-01 1.00000000e+00\n",
      "  3.89053882e-01 6.05667154e-01 6.66666667e-01 3.65000000e-01]\n",
      " [3.95833333e-01 3.65461032e-01 6.33344117e-01 2.96144111e-01\n",
      "  7.81470292e-06 1.21101661e-01 6.88710327e-01 0.00000000e+00\n",
      "  1.18795078e-02 2.64291606e-01 6.66666667e-01 6.00000000e-01]\n",
      " [5.72916667e-01 4.46786438e-01 4.26291384e-01 4.25301166e-01\n",
      "  0.00000000e+00 5.97407857e-02 6.62376449e-01 1.00000000e+00\n",
      "  2.34196012e-01 9.00508181e-01 6.66666667e-01 4.98000000e-01]\n",
      " [7.29166667e-02 3.33332477e-01 7.48732880e-01 5.43444829e-01\n",
      "  0.00000000e+00 3.24625354e-01 7.81435919e-01 0.00000000e+00\n",
      "  6.04582096e-03 3.01907676e-01 6.66666667e-01 8.39000000e-01]\n",
      " [5.62500000e-01 5.84056975e-04 5.75110536e-01 8.94872165e-01\n",
      "  1.24874119e-06 3.17537465e-01 8.13719216e-01 0.00000000e+00\n",
      "  1.07127705e-02 3.71121458e-01 6.66666667e-01 6.43000000e-01]\n",
      " [3.02083333e-01 1.81598627e-03 3.90704195e-01 9.76971998e-01\n",
      "  1.44008056e-04 3.48926691e-01 7.85536514e-01 0.00000000e+00\n",
      "  1.11158252e-01 4.60886421e-01 6.66666667e-01 5.11000000e-01]\n",
      " [5.52083333e-01 7.58233906e-05 4.71584169e-01 9.62954953e-01\n",
      "  0.00000000e+00 9.98379911e-02 8.19668634e-01 0.00000000e+00\n",
      "  8.88841748e-02 5.62783025e-01 6.66666667e-01 4.71000000e-01]\n",
      " [2.18750000e-01 9.04618351e-01 5.02857759e-01 7.68774830e-02\n",
      "  0.00000000e+00 9.88254354e-02 3.79956861e-01 0.00000000e+00\n",
      "  1.64191769e-01 2.75849408e-01 6.66666667e-01 3.03000000e-01]\n",
      " [6.14583333e-01 9.46659851e-03 3.30313814e-01 8.24786941e-01\n",
      "  0.00000000e+00 9.88254354e-02 8.14785845e-01 1.00000000e+00\n",
      "  1.89859992e-02 6.90328589e-01 6.66666667e-01 1.20000000e-01]\n",
      " [3.75000000e-01 4.08622212e-02 8.17750458e-01 4.86375433e-01\n",
      "  1.31923464e-04 6.76387201e-02 7.41141056e-01 0.00000000e+00\n",
      "  5.38820535e-02 4.50929892e-01 6.66666667e-01 7.78000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "#impute missing values\n",
    "test_x[\"duration_ms\"]=test_x[\"duration_ms\"].replace(-1,np.NaN)\n",
    "test_x[\"duration_ms\"] = dms_imputer.transform(test_x[[\"duration_ms\"]])\n",
    "test_x[\"tempo\"] = tempo_imputer.transform(test_x[[\"tempo\"]])\n",
    "test_x_final=min_max_scaler.transform(test_x)\n",
    "test_x_final=selector.transform(test_x_final)\n",
    "\n",
    "print(test_x_final[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5593574a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronic' 'Soul' \"Children's Music\" 'Movie' \"Children's Music\" 'Ska'\n",
      " 'Alternative' 'Movie' 'Alternative' 'Ska']\n"
     ]
    }
   ],
   "source": [
    "#apply the trained model to test data\n",
    "y_pred=rfmodel.predict(test_x_final) #random forest\n",
    "#y_pred=mlpmodel.predict(test_x_final) #mlp\n",
    "y_pred=genre_encoder.inverse_transform(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4a4e64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        instance_id             genre\n",
       "0                1        Electronic\n",
       "1                2              Soul\n",
       "2                3  Children's Music\n",
       "3                4             Movie\n",
       "4                5  Children's Music\n",
       "...            ...               ...\n",
       "30926        30927             Movie\n",
       "30927        30928       Alternative\n",
       "30928        30929              Folk\n",
       "30929        30930              Folk\n",
       "30930        30931       Alternative\n",
       "\n",
       "[30931 rows x 2 columns]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save prediction to csv - ready to upload to kaggle\n",
    "instance_id=df_test[\"instance_id\"]\n",
    "prediction=pd.DataFrame(instance_id)\n",
    "prediction[\"genre\"]=y_pred\n",
    "prediction.to_csv(\"ass3data/preds.csv\", index=False)\n",
    "prediction.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3bb20c",
   "metadata": {},
   "source": [
    "Further Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4de9617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Feature Importance\n",
      "#1: acousticness \n",
      "#2: danceability \n",
      "#3: duration_ms \n",
      "#4: energy \n",
      "#5: instrumentalness \n",
      "#6: key \n",
      "#7: loudness \n",
      "#8: speechiness \n",
      "#9: popularity \n",
      "#10: mode \n",
      "#11: tempo \n",
      "#12: liveness \n"
     ]
    }
   ],
   "source": [
    "#Feature importance\n",
    "from sklearn.feature_selection import RFE\n",
    "ranker = RFE(rfmodel, n_features_to_select=1)\n",
    "ranker.fit(train_x_final, train_y_encoded)\n",
    "print(f\"Model's Feature Importance\")\n",
    "for i in range(len(ranker.ranking_)):\n",
    "    print(f\"#{i+1}: {train_x_clean.columns[ranker.ranking_[i]-1]} \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd79be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
